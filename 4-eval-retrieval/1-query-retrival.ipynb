{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "990ff8d8",
   "metadata": {},
   "source": [
    "# Evaluation Retrival\n",
    "\n",
    "Um ganze sätze zu prüfen und zu vergleichen wird ebenfalls ein Cosinus-Similarity genutzt. Hierzu werden die Sätze in Vektoren umgewandelt und dann verglichen.\n",
    "\n",
    "Die Testdaten wurden von Claude Code anhand der Produktdatei generiert. Sinnvoll wäre es, mit dem Kunden zu sprechen und echte Fragen zu sammeln.\n",
    "\n",
    "prdukt_chunks muss so ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18565be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name deepset/gbert-large. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"../3-indexing/chroma_db\")\n",
    "collection = client.get_collection('prdukt_chunks')\n",
    "model = SentenceTransformer('deepset/gbert-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd450170",
   "metadata": {},
   "source": [
    "## Queries\n",
    "\n",
    "Alle Queries wurden mit einem LLM erstellt, die Kategorien sind von mir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e62819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geladene Queries: 61\n"
     ]
    }
   ],
   "source": [
    "with open('test_queries.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "all_queries = []\n",
    "for category_name, query_list in test_data['queries'].items():\n",
    "    for query_obj in query_list:\n",
    "        all_queries.append(query_obj['query'])\n",
    "\n",
    "print(f\"Geladene Queries: {len(all_queries)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab908b3",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e475802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(queries, top_k=10):\n",
    "    \n",
    "    queries_embedded = model.encode(queries, normalize_embeddings=True, show_progress_bar=True)\n",
    "    results = []\n",
    "    \n",
    "    for i, query in enumerate(queries):\n",
    "\n",
    "        result = collection.query(\n",
    "            query_embeddings=[queries_embedded[i].tolist()], \n",
    "            n_results=top_k\n",
    "        )\n",
    "\n",
    "        for rank, (doc, dist, meta) in enumerate(\n",
    "            zip(\n",
    "                result['documents'][0], \n",
    "                result['distances'][0],\n",
    "                result['metadatas'][0]\n",
    "            ), \n",
    "            start=1\n",
    "        ):\n",
    "            results.append({\n",
    "                'query': query,\n",
    "                'rank': rank,\n",
    "                'document': doc,\n",
    "                'distance': dist,\n",
    "                'chunk_type': meta.get('chunk_type'),\n",
    "                'spec_categorie': meta.get('spec_category'),\n",
    "                'product_id': meta.get('product_id'),\n",
    "                'product_manufacturer': meta.get('product_manufacturer')\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9846c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:06<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 query  rank  \\\n",
      "0    Wie hoch ist der Energieverbrauch des HMFvh 40...     1   \n",
      "1    Wie hoch ist der Energieverbrauch des HMFvh 40...     2   \n",
      "2    Wie hoch ist der Energieverbrauch des HMFvh 40...     3   \n",
      "3    Wie hoch ist der Energieverbrauch des HMFvh 40...     4   \n",
      "4    Wie hoch ist der Energieverbrauch des HMFvh 40...     5   \n",
      "..                                                 ...   ...   \n",
      "605                   Ultra-efficient Energieeffizienz     6   \n",
      "606                   Ultra-efficient Energieeffizienz     7   \n",
      "607                   Ultra-efficient Energieeffizienz     8   \n",
      "608                   Ultra-efficient Energieeffizienz     9   \n",
      "609                   Ultra-efficient Energieeffizienz    10   \n",
      "\n",
      "                                              document  distance   chunk_type  \\\n",
      "0    Mit einem jährlichen Energieverbrauch von nur ...  0.085498  description   \n",
      "1    Mit einem Energieverbrauch von 0,98 kWh pro Ta...  0.092091  description   \n",
      "2    Der Innenbehälter des MED-340 besteht aus glat...  0.092141  description   \n",
      "3    Mit einem jährlichen Energieverbrauch von nur ...  0.092763  description   \n",
      "4    Mit einem jährlichen Energieverbrauch von 1.16...  0.092790  description   \n",
      "..                                                 ...       ...          ...   \n",
      "605  Energie - Leistungsaufnahme-watt: 180, Normalv...  0.231721        specs   \n",
      "606            Energie - Normalverbrauch-kwh 24h: 0.85  0.232281        specs   \n",
      "607           Energie - Normalverbrauch-kwh 24h: 0.512  0.232508        specs   \n",
      "608  Mit einem jährlichen Energieverbrauch von 156 ...  0.234248  description   \n",
      "609  Der Kirsch MED-520 ist speziell für die Anford...  0.234458  description   \n",
      "\n",
      "    spec_categorie                                         product_id  \\\n",
      "0             None  HMTvh-1501-Perfection-Medikamentenkuehlgeraet-...   \n",
      "1             None                   LKexv-5400-MediLine-10-bis-150-C   \n",
      "2             None   Kirsch-MED-340-ULTIMATE-Medikamentenkuehlschrank   \n",
      "3             None  HMTvh-1511-Perfection-Medikamentenkuehlgeraet-...   \n",
      "4             None  SFPvg-1402-Performance-Laborgefriergeraet-mit-...   \n",
      "..             ...                                                ...   \n",
      "605           None            Haier-Medikamentenkuehlschrank-HYC-85GD   \n",
      "606           None                      LKv-3910-MediLine-30-bis-160C   \n",
      "607           None  HMTvh-1511-Perfection-Medikamentenkuehlgeraet-...   \n",
      "608           None  SRTfg-1501-Performance-Laborkuehlgeraet-mit-zu...   \n",
      "609           None  Kirsch-MED-520-PRO-ACTIVE-Medikamentenkuehlsch...   \n",
      "\n",
      "    product_manufacturer  \n",
      "0               Liebherr  \n",
      "1               Liebherr  \n",
      "2                 Kirsch  \n",
      "3               Liebherr  \n",
      "4               Liebherr  \n",
      "..                   ...  \n",
      "605                Haier  \n",
      "606             Liebherr  \n",
      "607             Liebherr  \n",
      "608             Liebherr  \n",
      "609               Kirsch  \n",
      "\n",
      "[610 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df = retrieve(all_queries)\n",
    "\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456283ea",
   "metadata": {},
   "source": [
    "## Metriken\n",
    "\n",
    "### Distance Metrics\n",
    "\n",
    "Zeigt wie gut die Retivals sind.\n",
    "\n",
    "L2-Distanz (Euklidean Distance) zwischen Query und Retrival Chunk im normalisierten Vektorspace. Je kleiner desto besser (0 = identisch, ~0,2 = sehr ähnlich, ...). \n",
    "\n",
    "- Ranking: Statistiken pro Rang\n",
    "- Distance Gap: Abstand zwischen ersten und zehnten Rang\n",
    "- Strong Results: Erbenisse mit einer Similarity > 0,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0982d0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking\n",
      "          mean    median       std       min       max\n",
      "rank                                                  \n",
      "1     0.144126  0.142331  0.050768  0.064345  0.260699\n",
      "2     0.149078  0.143932  0.051139  0.064511  0.260901\n",
      "3     0.151926  0.145612  0.051766  0.064543  0.261605\n",
      "4     0.154018  0.145864  0.052049  0.069653  0.262764\n",
      "5     0.155780  0.146535  0.053114  0.069905  0.279184\n",
      "6     0.157355  0.147976  0.053973  0.070319  0.294403\n",
      "7     0.158463  0.148960  0.054565  0.070865  0.303758\n",
      "8     0.159325  0.149165  0.054821  0.071318  0.306031\n",
      "9     0.160068  0.149983  0.054991  0.071343  0.306102\n",
      "10    0.160858  0.151353  0.055217  0.071368  0.309042\n",
      "\n",
      "\n",
      "Distance Gap (Rank 1 -> 10): 0.0167\n",
      "Strong Results: 606/610 (99.3%)\n"
     ]
    }
   ],
   "source": [
    "distance_stats = df.groupby('rank')['distance'].agg(['mean','median','std','min','max'])\n",
    "print(\"Ranking\")\n",
    "print(distance_stats)\n",
    "print(\"\\n\")\n",
    "\n",
    "rank01_mean = df[df['rank'] == 1]['distance'].mean()\n",
    "rank10_mean = df[df['rank'] == 10]['distance'].mean()\n",
    "gap = rank10_mean - rank01_mean\n",
    "print(f\"Distance Gap (Rank 1 -> 10): {gap:.4f}\")\n",
    "\n",
    "# Cousin Sim\n",
    "high_confidence = (df['distance'] < 0.3).sum()\n",
    "total = len(df)\n",
    "print(f\"Strong Results: {high_confidence}/{total} ({high_confidence/total*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fbdab8",
   "metadata": {},
   "source": [
    "### Consistency & Stability\n",
    "\n",
    "- Tied Sum: Anzahl der Results mit gleicher Distanz -> Führtdazu, dass das Model nicht gut unterscheiden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a264cea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tied Sum: 0\n"
     ]
    }
   ],
   "source": [
    "duplicate_distances = df.groupby(['query', 'distance']).size()\n",
    "ties = (duplicate_distances > 1).sum()\n",
    "print(f\"Tied Sum: {ties}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16778b6a",
   "metadata": {},
   "source": [
    "### Coverage\n",
    "\n",
    "Anzahl der unterschiedlichen Chunks über alle Queries -> Zeigt die Abdeckung der Daten in der DB - oder ob immer die selben Chunks gefunden werden.\n",
    "\n",
    "- Unique Chunks: Anzahl der Chunks sie einmalig gefunden wurden\n",
    "- Most Wanted: Eigentlich die am häufigsten gefundenen Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68d88deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Chunks: 339/1800 (18.8%)\n",
      "\n",
      "\n",
      "Most Wanted\n",
      "11x: Sonstiges - Netzkabel: 300, Zubehör: Edelstahlregale TT90-RC für bis zu 72 Standard-Cryoboxen, Optio...\n",
      "9x: Sonstiges - Netzkabel: 300, Zubehör: Edelstahlregale TT90-RC, Wifi-Bridge, Optionen: Rollen, Umluftv...\n",
      "9x: Sonstiges - Netzkabel: 300, Zubehör: Edelstahlregale TT90-RC, Optionen: vier Rollen fest montiert, z...\n",
      "8x: Sonstiges - Netzkabel: 300, Zubehör: Edelstahlregale TT90-RC für bis zu 72 Standard-Cryoboxen, Wifi-...\n",
      "8x: Sonstiges - flexible Ausstattung: True...\n"
     ]
    }
   ],
   "source": [
    "unique_chunks = df['document'].nunique()\n",
    "total_chunks_in_db = collection.count()\n",
    "coverage = unique_chunks / total_chunks_in_db * 100\n",
    "print(f\"Unique Chunks: {unique_chunks}/{total_chunks_in_db} ({coverage:.1f}%)\")\n",
    "print(\"\\n\")\n",
    "\n",
    "chunk_frequency = df['document'].value_counts()\n",
    "most_common = chunk_frequency.head(5)\n",
    "print(\"Most Wanted\")\n",
    "for doc, count in most_common.items():\n",
    "    print(f\"{count}x: {doc[:100]}...\")\n",
    "\n",
    "# Additional checks because specs seems prefered\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
